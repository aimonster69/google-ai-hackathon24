{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installations\n",
    "# pip install -q -U google-generativeai\n",
    "# pip install pandas\n",
    "# pip install seaborn\n",
    "# pip install nltk\n",
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavishyapandit/VSCProjects/google-ai-hackathon24/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import traceback\n",
    "import nltk\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input: Getting table description\n",
    "# table_description = input('Table/Data description')\n",
    "table_description = \"\"\"The US Census Bureau's world population clock estimated that the global population as of September 2022 was 7,922,312,800 people and was expected to reach 8 billion by mid-November of 2022. This total far exceeds the 2015 world population of 7.2 billion. The world's population continues to increase by roughly 140 people per minute, with births outweighing deaths in most countries.\n",
    "Overall, however, the rate of population growth has been slowing for several decades. This slowdown is expected to continue until the rate of population growth reaches zero (an equal number of births and deaths) around 2080-2100, at a population of approximately 10.4 billion people. After this time, the population growth rate is expected to turn negative, resulting in global population decline.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>area</th>\n",
       "      <th>landAreaKm</th>\n",
       "      <th>cca2</th>\n",
       "      <th>cca3</th>\n",
       "      <th>netChange</th>\n",
       "      <th>growthRate</th>\n",
       "      <th>worldPercentage</th>\n",
       "      <th>density</th>\n",
       "      <th>densityMi</th>\n",
       "      <th>place</th>\n",
       "      <th>pop1980</th>\n",
       "      <th>pop2000</th>\n",
       "      <th>pop2010</th>\n",
       "      <th>pop2022</th>\n",
       "      <th>pop2023</th>\n",
       "      <th>pop2030</th>\n",
       "      <th>pop2050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>3287590.0</td>\n",
       "      <td>2973190.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IND</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>480.5033</td>\n",
       "      <td>1244.5036</td>\n",
       "      <td>356</td>\n",
       "      <td>696828385</td>\n",
       "      <td>1059633675</td>\n",
       "      <td>1240613620</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>1428627663</td>\n",
       "      <td>1514994080</td>\n",
       "      <td>1670490596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2</td>\n",
       "      <td>9706961.0</td>\n",
       "      <td>9424702.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>CHN</td>\n",
       "      <td>-0.0113</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.1781</td>\n",
       "      <td>151.2696</td>\n",
       "      <td>391.7884</td>\n",
       "      <td>156</td>\n",
       "      <td>982372466</td>\n",
       "      <td>1264099069</td>\n",
       "      <td>1348191368</td>\n",
       "      <td>1425887337</td>\n",
       "      <td>1425671352</td>\n",
       "      <td>1415605906</td>\n",
       "      <td>1312636325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>9372610.0</td>\n",
       "      <td>9147420.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>37.1686</td>\n",
       "      <td>96.2666</td>\n",
       "      <td>840</td>\n",
       "      <td>223140018</td>\n",
       "      <td>282398554</td>\n",
       "      <td>311182845</td>\n",
       "      <td>338289857</td>\n",
       "      <td>339996563</td>\n",
       "      <td>352162301</td>\n",
       "      <td>375391963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4</td>\n",
       "      <td>1904569.0</td>\n",
       "      <td>1877519.0</td>\n",
       "      <td>ID</td>\n",
       "      <td>IDN</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>147.8196</td>\n",
       "      <td>382.8528</td>\n",
       "      <td>360</td>\n",
       "      <td>148177096</td>\n",
       "      <td>214072421</td>\n",
       "      <td>244016173</td>\n",
       "      <td>275501339</td>\n",
       "      <td>277534122</td>\n",
       "      <td>292150100</td>\n",
       "      <td>317225213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>5</td>\n",
       "      <td>881912.0</td>\n",
       "      <td>770880.0</td>\n",
       "      <td>PK</td>\n",
       "      <td>PAK</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>311.9625</td>\n",
       "      <td>807.9829</td>\n",
       "      <td>586</td>\n",
       "      <td>80624057</td>\n",
       "      <td>154369924</td>\n",
       "      <td>194454498</td>\n",
       "      <td>235824862</td>\n",
       "      <td>240485658</td>\n",
       "      <td>274029836</td>\n",
       "      <td>367808468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  rank       area  landAreaKm cca2 cca3  netChange  \\\n",
       "0          India     1  3287590.0   2973190.0   IN  IND     0.4184   \n",
       "1          China     2  9706961.0   9424702.9   CN  CHN    -0.0113   \n",
       "2  United States     3  9372610.0   9147420.0   US  USA     0.0581   \n",
       "3      Indonesia     4  1904569.0   1877519.0   ID  IDN     0.0727   \n",
       "4       Pakistan     5   881912.0    770880.0   PK  PAK     0.1495   \n",
       "\n",
       "   growthRate  worldPercentage   density  densityMi  place    pop1980  \\\n",
       "0      0.0081           0.1785  480.5033  1244.5036    356  696828385   \n",
       "1     -0.0002           0.1781  151.2696   391.7884    156  982372466   \n",
       "2      0.0050           0.0425   37.1686    96.2666    840  223140018   \n",
       "3      0.0074           0.0347  147.8196   382.8528    360  148177096   \n",
       "4      0.0198           0.0300  311.9625   807.9829    586   80624057   \n",
       "\n",
       "      pop2000     pop2010     pop2022     pop2023     pop2030     pop2050  \n",
       "0  1059633675  1240613620  1417173173  1428627663  1514994080  1670490596  \n",
       "1  1264099069  1348191368  1425887337  1425671352  1415605906  1312636325  \n",
       "2   282398554   311182845   338289857   339996563   352162301   375391963  \n",
       "3   214072421   244016173   275501339   277534122   292150100   317225213  \n",
       "4   154369924   194454498   235824862   240485658   274029836   367808468  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching credentials\n",
    "f = open('credentials.json', 'r')\n",
    "creds = json.load(f)\n",
    "gemini_token = creds['gemini_api']\n",
    "\n",
    "df = pd.read_csv('data/countries_population/countries-table.csv', encoding='unicode_escape')\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, temperature, safety_setting):\n",
    "    generation_config = {\n",
    "      \"temperature\": temperature,\n",
    "      \"top_p\": 1,\n",
    "      \"top_k\": 1,\n",
    "    }\n",
    "    safety_settings = [\n",
    "        {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": safety_setting\n",
    "        },\n",
    "        {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": safety_setting\n",
    "        },\n",
    "        {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": safety_setting\n",
    "        },\n",
    "        {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": safety_setting\n",
    "        },\n",
    "    ]\n",
    "    genai.configure(api_key=gemini_token)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
    "                                    generation_config=generation_config,\n",
    "                                    safety_settings=safety_settings)\n",
    "    convo = model.start_chat(history=[])\n",
    "    convo.send_message(prompt)\n",
    "    return re.sub(r\"\\*\\*([^*]+)\\*\\*\", r\"\\1\", convo.last.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dict={\n",
      "'tbl_description': 'The table contains data about the world population as of September 2022, including estimates for future population growth and decline.', \n",
      "'columns': {\n",
      "            'country': {'col_description':'Name of the country', 'data_type':'object'},\n",
      "            'rank': {'col_description':'Rank of the country by population', 'data_type':'int64'},\n",
      "            'area': {'col_description':'Total area of the country in square kilometers', 'data_type':'float64'},\n",
      "            'landAreaKm': {'col_description':'Land area of the country in square kilometers', 'data_type':'float64'},\n",
      "            'cca2': {'col_description':'Two-letter country code', 'data_type':'object'},\n",
      "            'cca3': {'col_description':'Three-letter country code', 'data_type':'object'},\n",
      "            'netChange': {'col_description':'Net change in population since the previous year', 'data_type':'float64'},\n",
      "            'growthRate': {'col_description':'Annual population growth rate', 'data_type':'float64'},\n",
      "            'worldPercentage': {'col_description':'Percentage of the world population', 'data_type':'float64'},\n",
      "            'density': {'col_description':'Population density per square kilometer', 'data_type':'float64'},\n",
      "            'densityMi': {'col_description':'Population density per square mile', 'data_type':'float64'},\n",
      "            'place': {'col_description':'Place of the country in the world by population', 'data_type':'int64'},\n",
      "            'pop1980': {'col_description':'Population in 1980', 'data_type':'int64'},\n",
      "            'pop2000': {'col_description':'Population in 2000', 'data_type':'int64'},\n",
      "            'pop2010': {'col_description':'Population in 2010', 'data_type':'int64'},\n",
      "            'pop2022': {'col_description':'Population in 2022', 'data_type':'int64'},\n",
      "            'pop2023': {'col_description':'Estimated population in 2023', 'data_type':'int64'},\n",
      "            'pop2030': {'col_description':'Estimated population in 2030', 'data_type':'int64'},\n",
      "            'pop2050': {'col_description':'Estimated population in 2050', 'data_type':'int64'}\n",
      "        }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "create_data_dict = f'''Table description: {table_description}\n",
    "Columns: {df.columns}\n",
    "Data types: {df.dtypes}\n",
    "\n",
    "Instruction:\n",
    "1. Based on the above mentioned details create a data dictionary which a small description of table, each column and the data type of each column.\n",
    "2. Don't generate anything else. Be concrete and concise in your response\n",
    "3. Give the output in the expected format of a dictionary only!\n",
    "'''\n",
    "output = '''\n",
    "Expected Output -> \n",
    "data_dict={\n",
    "'tbl_description': 'description of table', \n",
    "'columns': {\n",
    "            'Name of the column 1': {'col_description':'description of column 1', 'data_type':'Data Type of the column 1'},\n",
    "            'Name of the column 2': {'col_description':'description of column 2', 'data_type':'Data Type of the column 2'},\n",
    "            'Name of the column 3': {'col_description':'description of column 3', 'data_type':'Data Type of the column 3'}\n",
    "        }\n",
    "}'''\n",
    "\n",
    "create_data_dict+=output\n",
    "\n",
    "response = generate_response(create_data_dict, 0, 'BLOCK_NONE')\n",
    "print(response)\n",
    "exec(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safety setting has been set to:  BLOCK_MEDIUM_AND_ABOVE\n"
     ]
    }
   ],
   "source": [
    "safety_setting = 'BLOCK_MEDIUM_AND_ABOVE'\n",
    "temperature = 0\n",
    "identify_threat_level = f'''\n",
    "\n",
    "Role: You are Gemini\n",
    "\n",
    "Action: Based on harm categories identify the level of threat as: LOW, MEDIUM or HIGH\n",
    "Data: {df.head()}\n",
    "Harm categories: HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_HATE_SPEECH, HARM_CATEGORY_DANGEROUS_CONTENT\n",
    "\n",
    "Instructions:\n",
    "1. Restrict your response to only LOW, MEDIUM or HIGH at all costs\n",
    "\n",
    "Expected output format: LOW or HIGH etc.'''\n",
    "\n",
    "threat_level = generate_response(identify_threat_level, temperature, 'BLOCK_NONE')\n",
    "\n",
    "if threat_level=='HIGH':\n",
    "    print('Taking user consent..')\n",
    "    safety_setting = 'BLOCK_NONE'\n",
    "print('Safety setting has been set to: ', safety_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If user want's suggestions of different types of analysis\n",
    "# prompt = f'''{table_description}\\n Refer {data_dict['columns'].keys()} and tell me the different analysis that can be done from the available columns keeping the given use case in mind.\n",
    "# Focus on Exploratory Data Analysis only. \n",
    "\n",
    "# Unique values in categorical column: {df.select_dtypes(include='object').nunique()}\n",
    "# Unique values in numerical column: {df.select_dtypes(include='number').nunique()}\n",
    "\n",
    "# Instructions:\n",
    "# 1. Keep your response consise and concrete\n",
    "# 2. Give your suggestions in bullet points\n",
    "# 3. Mention the columns that will help in the completion of the respective analysis\n",
    "# 4. Make the analysis rich by including as many important columns as possible. Don't include columns with no/very little variance.\n",
    "# 5. Every new type of analysis in the response should be represented with \">>\" at all costs\n",
    "# 6. The analysis should be complex but at the same time either convey action items or actionable insights\n",
    "# 7. Don't generate a column name by your own. Use only the columns: {data_dict['columns'].keys()}\n",
    "# 8. Don't mention the columns in \"\" or ''.\n",
    "# 9. Don't add anything else to your response, except for Analysis name and the relevant columns\n",
    "# 10. Give the response in the expected format only.\n",
    "# 11. The analysis should be suggested from the growth/impact to the business - perspective\n",
    "\n",
    "\n",
    "# Expected output:\n",
    "# >> Analysis 1\n",
    "# - Columns: A, B, C etc.\n",
    "\n",
    "# >> Analysis 2\n",
    "# - Columns: A, C, E etc.\n",
    "# etc.\n",
    "# '''\n",
    "\n",
    "# types_of_analysis = generate_response(prompt, 0.5)\n",
    "# print(types_of_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # User selects an analysis to perform\n",
    "# list_of_analyses = types_of_analysis.split('>> ')[1:]\n",
    "# my_analysis = list_of_analyses[0]\n",
    "# my_analysis = my_analysis.replace('\\n','')\n",
    "# my_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: country, rank, pop2022, pop2023, pop2030, pop2050\n"
     ]
    }
   ],
   "source": [
    "# If user wants to give his own analysis\n",
    "my_analysis = '''Top 15 countries by population'''\n",
    "my_analysis += \"\\nAlways Include: Relevant numbers/figures associated with the analysis.\"\n",
    "\n",
    "identify_colums = f'''Analysis: {my_analysis}\n",
    "Remember: Almmost every analysis requires some kind of aggregation or grouping.\n",
    "First 5 rows of Dataframe for your reference: {df.head()}\n",
    "\n",
    "Instructions:\n",
    "1. Based on the Analysis mentioned, Give the names of the most relevant columns from {data_dict} by studying details about each column description.\n",
    "2. Don't generate any column(s) of your own\n",
    "3. If the analysis request is not direct then identify a logic from the given columns that would help you with the analysis.\n",
    "4. Don't write anything else, just the column names.\n",
    "\n",
    "Expected Output if relevant columns found:\n",
    "Columns: Col 1, Col 2, Col 3 etc.\n",
    "'''\n",
    "\n",
    "column_names = generate_response(identify_colums, 0, safety_setting)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'rank', 'pop2022', 'pop2023', 'pop2030', 'pop2050']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns to work on\n",
    "# Find the index of \"Columns:\"\n",
    "columns_index = column_names.find(\"Columns:\")\n",
    "\n",
    "# Extract the text after \"Columns:\"\n",
    "columns_text = column_names[columns_index + len(\"Columns:\"):].strip()\n",
    "\n",
    "# Print the extracted text\n",
    "columns = columns_text.split(', ')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country: {'col_description': 'Name of the country', 'data_type': 'object'}\n",
      "rank: {'col_description': 'Rank of the country by population', 'data_type': 'int64'}\n",
      "pop2022: {'col_description': 'Population in 2022', 'data_type': 'int64'}\n",
      "pop2023: {'col_description': 'Estimated population in 2023', 'data_type': 'int64'}\n",
      "pop2030: {'col_description': 'Estimated population in 2030', 'data_type': 'int64'}\n",
      "pop2050: {'col_description': 'Estimated population in 2050', 'data_type': 'int64'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df[columns]\n",
    "data.head()\n",
    "columns_intel = ''\n",
    "for key, val in data_dict['columns'].items():\n",
    "    if key in columns:\n",
    "        columns_intel+=f'{key}: {val}\\n'\n",
    "\n",
    "print(columns_intel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numeric'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_check = f'''\n",
    "Top 5 rows: {data.head()}\n",
    "Data: {data.columns}\n",
    "\n",
    "Based on the above details tell me what type of data is it?\n",
    "Rules:\n",
    "1. If consists text data then write 'Text'\n",
    "2. Else 'Numeric'\n",
    "3. Don't write anything else just respond whether it is 'Text' or 'Numeric'\n",
    "'''\n",
    "\n",
    "template_to_choose = generate_response(template_check, 0, safety_setting)\n",
    "template_to_choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>pop2022</th>\n",
       "      <th>pop2023</th>\n",
       "      <th>pop2030</th>\n",
       "      <th>pop2050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>1428627663</td>\n",
       "      <td>1514994080</td>\n",
       "      <td>1670490596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2</td>\n",
       "      <td>1425887337</td>\n",
       "      <td>1425671352</td>\n",
       "      <td>1415605906</td>\n",
       "      <td>1312636325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>338289857</td>\n",
       "      <td>339996563</td>\n",
       "      <td>352162301</td>\n",
       "      <td>375391963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4</td>\n",
       "      <td>275501339</td>\n",
       "      <td>277534122</td>\n",
       "      <td>292150100</td>\n",
       "      <td>317225213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>5</td>\n",
       "      <td>235824862</td>\n",
       "      <td>240485658</td>\n",
       "      <td>274029836</td>\n",
       "      <td>367808468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  rank     pop2022     pop2023     pop2030     pop2050\n",
       "0          India     1  1417173173  1428627663  1514994080  1670490596\n",
       "1          China     2  1425887337  1425671352  1415605906  1312636325\n",
       "2  United States     3   338289857   339996563   352162301   375391963\n",
       "3      Indonesia     4   275501339   277534122   292150100   317225213\n",
       "4       Pakistan     5   235824862   240485658   274029836   367808468"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_high_missing_columns(df, missing_threshold=25):\n",
    "  \"\"\"Drops columns in a pandas DataFrame that have more than the specified missing value threshold.\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): The DataFrame to process.\n",
    "      missing_threshold (float, optional): The threshold for the proportion of missing values in a column. Defaults to 0.1 (10%).\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: The DataFrame with columns exceeding the missing value threshold dropped.\n",
    "  \"\"\"\n",
    "\n",
    "  # Calculate the percentage of missing values per column\n",
    "  missing_vals = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "  # Identify columns to drop\n",
    "  cols_to_drop = missing_vals[missing_vals > missing_threshold].index\n",
    "\n",
    "  # Drop the columns if any\n",
    "  if len(cols_to_drop) > 0:\n",
    "    return df.drop(cols_to_drop, axis=1)\n",
    "  else:\n",
    "    return df.copy()  # Return a copy to avoid modifying the original DataFrame\n",
    "\n",
    "data = drop_high_missing_columns(data, missing_threshold=25)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>pop2022</th>\n",
       "      <th>pop2023</th>\n",
       "      <th>pop2030</th>\n",
       "      <th>pop2050</th>\n",
       "      <th>iso_codes_alpha_3_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>1428627663</td>\n",
       "      <td>1514994080</td>\n",
       "      <td>1670490596</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2</td>\n",
       "      <td>1425887337</td>\n",
       "      <td>1425671352</td>\n",
       "      <td>1415605906</td>\n",
       "      <td>1312636325</td>\n",
       "      <td>CHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>338289857</td>\n",
       "      <td>339996563</td>\n",
       "      <td>352162301</td>\n",
       "      <td>375391963</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4</td>\n",
       "      <td>275501339</td>\n",
       "      <td>277534122</td>\n",
       "      <td>292150100</td>\n",
       "      <td>317225213</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>5</td>\n",
       "      <td>235824862</td>\n",
       "      <td>240485658</td>\n",
       "      <td>274029836</td>\n",
       "      <td>367808468</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  rank     pop2022     pop2023     pop2030     pop2050  \\\n",
       "0          India     1  1417173173  1428627663  1514994080  1670490596   \n",
       "1          China     2  1425887337  1425671352  1415605906  1312636325   \n",
       "2  United States     3   338289857   339996563   352162301   375391963   \n",
       "3      Indonesia     4   275501339   277534122   292150100   317225213   \n",
       "4       Pakistan     5   235824862   240485658   274029836   367808468   \n",
       "\n",
       "  iso_codes_alpha_3_generated  \n",
       "0                         IND  \n",
       "1                         CHN  \n",
       "2                         USA  \n",
       "3                         IDN  \n",
       "4                         PAK  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycountry as pc\n",
    "\n",
    "fetch_column = f'''Refer columns info: {columns_intel}\n",
    "And tell which column refers to countries.\n",
    "Instructions: Don't generate anything else but the column name.\n",
    "\n",
    "Expected output: Column name - else: '' '''\n",
    "\n",
    "iso_codes = []\n",
    "country_col = generate_response(fetch_column, 0, safety_setting)\n",
    "print(country_col)\n",
    "if country_col!='':\n",
    "    def add_iso_codes(df):\n",
    "        for country in df[f'{country_col}']:\n",
    "            country_region = pc.countries.get(name=country)\n",
    "            if country_region:\n",
    "                iso_code = country_region.alpha_3\n",
    "            else:\n",
    "                iso_code = country\n",
    "            iso_codes.append(iso_code)\n",
    "        df['iso_codes_alpha_3_generated'] = iso_codes\n",
    "        return df\n",
    "    data = add_iso_codes(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Imputation', 'Feature Scaling', 'Noise Reduction', 'Feature Engineering', 'Data Normalization or Standardization']\n"
     ]
    }
   ],
   "source": [
    "# Prompt Template for numeric data - \n",
    "if template_to_choose=='Numeric':\n",
    "    preprocessing_template = '''\n",
    "    > Data Imputation:-\n",
    "        When to use: Data imputation is used to fill in missing values (e.g. Null, None or NaN) in the dataset. Impute mode for categorical and mean/median otherwise.\n",
    "        For what type of data: This step is applicable to numerical and categorical data.\n",
    "\n",
    "    > Feature Scaling:-\n",
    "\n",
    "        When to use: Feature scaling is can be done when the features in the dataset have different scales. \n",
    "        Do not scale columns/features that are ordinal in nature like rank, ratings etc at any cost!\n",
    "        For what type of data: This step is primarily applicable to numerical data, but it can also be used for some types of categorical data.\n",
    "\n",
    "    > Noise Reduction:-\n",
    "\n",
    "        When to use: Noise in the data can arise from various sources, such as measurement errors or data collection processes. Noise reduction techniques aim to remove or minimize the impact of noise on the dataset.\n",
    "        For what type of data: This step is applicable to numerical data, and categorical data.\n",
    "\n",
    "        Actions:\n",
    "        For numerical data, apply smoothing techniques such as moving averages or median filters.\n",
    "        For categorical data, grouping rare categories or merging similar categories can reduce noise.\n",
    "\n",
    "    > Feature Engineering:-\n",
    "\n",
    "        When to use: Feature engineering involves creating new features from existing ones or transforming existing features.\n",
    "        Remember: Do it only when it would help in the analysis.\n",
    "        For E.g 1 If column like date is involved then make sure the column has a consistent format i.e. \"datetime format\"\n",
    "        For what type of data: This step is applicable to all types of data.\n",
    "\n",
    "        Actions:\n",
    "        Generate new features by combining existing ones, extracting useful information from variables, or creating interaction terms.\n",
    "        Transform features using mathematical functions such as logarithms, square roots, or polynomial transformations to better capture non-linear relationships.\n",
    "\n",
    "    > Data Normalization or Standardization:-\n",
    "\n",
    "        When to use: Normalization or standardization can be applied to scale numerical data to a standard range or distribution if required. \n",
    "        You shouldn't do it to columns that are ordinal in nature like rank, rating etc, educational level etc.\n",
    "        For what type of data: This step is applicable to numerical data\n",
    "\n",
    "        Actions:\n",
    "        Scale numerical features to a specific range (e.g., [0, 1]) using min-max scaling or standardize features to have a mean of 0 and standard deviation of 1 using z-score normalization.\n",
    "\n",
    "    > '''\n",
    "\n",
    "    pattern = r'> (.*?):-'\n",
    "    preprocessing_steps = re.findall(pattern, preprocessing_template)\n",
    "    prep_details = preprocessing_template.split('>')[1:-1]\n",
    "\n",
    "    # Print the extracted text\n",
    "    print(preprocessing_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if template_to_choose=='Text':\n",
    "    # Prompt Template for Text data - \n",
    "    preprocessing_template = '''\n",
    "    > Data Cleaning:-\n",
    "\n",
    "        When to use: Should be performed to remove stop words or punctuation marks from text data.\n",
    "        For what type of data: This step is applicable to textual data.\n",
    "        \n",
    "        Actions:\n",
    "        Remove irrelevant information from text data, such as stop words or punctuation marks.\n",
    "\n",
    "    > Data Imputation:-\n",
    "\n",
    "        When to use: Data imputation is used to fill in missing values (e.g. Null, None or NaN) in the dataset. Impute mode for categorical and mean/median otherwise.\n",
    "        For what type of data: This step is applicable to numerical and categorical data. Text data cleaning techniques can sometimes address missing values, but imputation might be necessary in specific cases.\n",
    "\n",
    "    > Text Preprocessing:-\n",
    "\n",
    "        When to use: Text preprocessing involves cleaning and transforming textual data into a format suitable for analysis. \n",
    "        Remember you need to do it only when the text is a sentence(s) and not for categorical data. Identify if the data is categorical or not.\n",
    "        For what type of data: This step is specific to textual data, such as natural language text.\n",
    "\n",
    "        Actions:\n",
    "        Lowercase all text\n",
    "        Apply stemming or lemmatization to reduce words to their root form (if applicable)\n",
    "\n",
    "    > Noise Reduction:-\n",
    "\n",
    "        When to use: Noise in the data can arise from various sources, such as measurement errors or data collection processes. Noise reduction techniques aim to remove or minimize the impact of noise on the dataset.\n",
    "        For what type of data: This step is applicable to numerical data, textual data, and categorical data.\n",
    "\n",
    "        Actions:\n",
    "        For numerical data, apply smoothing techniques such as moving averages or median filters.\n",
    "        For categorical data, grouping rare categories or merging similar categories can reduce noise.\n",
    "\n",
    "    > Feature Engineering:-\n",
    "\n",
    "        When to use: Feature engineering involves creating new features from existing ones or transforming existing features to improve the performance of machine learning models. For E.g. If a feature like date is involved and if the data is on a daily basis - aggregate it to weekly or monthly basis for better analysis unless not a stock price data.\n",
    "        For what type of data: This step is applicable to all types of data.\n",
    "        Remember: Do it only when it would help in the analysis.\n",
    "        For E.g 1 If column like date is involved then make sure the column has a consistent format i.e. \"datetime format\"\n",
    "        For what type of data: This step is applicable to all types of data.\n",
    "\n",
    "        Actions:\n",
    "        Generate new features by combining existing ones, extracting useful information from text or categorical variables, or creating interaction terms.\n",
    "        Transform features using mathematical functions such as logarithms, square roots, or polynomial transformations to better capture non-linear relationships.\n",
    "        Apply techniques specific to text data, such as TF-IDF (Term Frequency-Inverse Document Frequency) to weight the importance of words.\n",
    "\n",
    "    > Data Normalization or Standardization:-\n",
    "\n",
    "        When to use: Normalization or standardization can be applied to scale numerical data to a standard range or distribution if required by the specific model being used. \n",
    "        You shouldn't do it to columns that are ordinal in nature like rank, rating etc, educational level etc.\n",
    "        For what type of data: This step is applicable to numerical data and is optional depending on the model's requirements.\n",
    "\n",
    "        Actions:\n",
    "        Scale numerical features to a specific range (e.g., [0, 1]) using min-max scaling or standardize features to have a mean of 0 and standard deviation of 1 using z-score normalization.\n",
    "\n",
    "    > '''\n",
    "\n",
    "    pattern = r'> (.*?):-'\n",
    "    preprocessing_steps = re.findall(pattern, preprocessing_template)\n",
    "    prep_details = preprocessing_template.split('>')[1:-1]\n",
    "\n",
    "    # Print the extracted text\n",
    "    print(preprocessing_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Data Imputation': False,\n",
       " 'Feature Scaling': False,\n",
       " 'Noise Reduction': '',\n",
       " 'Feature Engineering': True,\n",
       " 'Data Normalization or Standardization': ''}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking preprocessing steps\n",
    "temperature = 0\n",
    "preprocessing_dict = {}\n",
    "for idx, step in enumerate(tqdm(preprocessing_steps)):\n",
    "    step_to_take = f'''\n",
    "    Details -\n",
    "    Analysis to perform: \"{my_analysis}\"\n",
    "    Based on the analysis identify if preprocessing \"{step}\" is required or not\n",
    "    Columns: {columns_intel}\n",
    "    Data dypes: {data.dtypes}\n",
    "    Description of data: {data.describe()}\n",
    "    Preprocessing Details: {prep_details[idx]}\n",
    "    Remember: Almost all the type of analysis include aggregation/grouping of data. Based on that identify whether {step} preprocessing step is necessary or not.\n",
    "\n",
    "    Adhere to below instructions at all costs!\n",
    "    Instructions -\n",
    "    0. Consider the details shared above to make the rules for your preprocessing test if needed\n",
    "    1. Assume the dataframe \"data\" exists already\n",
    "    2. Do not read data from anywhere\n",
    "    3. Write a simple error free code\n",
    "    4. Write a function that performs the preprocessing test and returns the response of the function in 'True' or 'False'\n",
    "    5. Write only the code, don't include any other text/explanation in header or footer at any cost.\n",
    "    6. Install and Import whatever package is necessary\n",
    "    7. Keep the original dataframe intact. Don't overwrite it - at any cost\n",
    "    8. If preprocessing step is not applicable for the data mentioned then return 'False'\n",
    "\n",
    "    Expected Output:\n",
    "    def preprocessing_test(data):\n",
    "        # Preprocessing logic\n",
    "\n",
    "        return True or False based on the logic\n",
    "    result = preprocessing_test(data)\n",
    "    '''\n",
    "    count = 0\n",
    "\n",
    "    # Automated debugging\n",
    "    while count<2:\n",
    "        try:\n",
    "                if count==0:\n",
    "                    test_of_step = generate_response(step_to_take, temperature, safety_setting)\n",
    "                test_of_step = test_of_step.replace('python', '')\n",
    "                test_of_step = test_of_step.replace('`', '')\n",
    "                result = ''\n",
    "                exec(test_of_step)\n",
    "                preprocessing_dict[step] = result\n",
    "                break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            error_message = f'''\n",
    "            Code:\n",
    "            {test_of_step}\n",
    "            Traceback of the code: {traceback.format_exc()}\n",
    "\n",
    "            Adhere to below instructions at all costs!\n",
    "            Instruction:\n",
    "            1. Identify the cause of the error and rewrite the code - make it error free\n",
    "            2. Don't include any text in your response\n",
    "            3. Rewrite the code as a function\n",
    "            4. Follow these instructions by all means\n",
    "            '''\n",
    "            \n",
    "            temperature += 0.2\n",
    "            test_of_step = generate_response(test_of_step, temperature, safety_setting)\n",
    "            count+=1\n",
    "\n",
    "preprocessing_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prep Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Performing only those preprocessing steps that are required\n",
    "\n",
    "# to know how was preprocessing done - code_transcript\n",
    "code_transcript = ''\n",
    "temperature = 0\n",
    "for key, val in tqdm(preprocessing_dict.items()):\n",
    "    if val==True:\n",
    "        write_code_for_prep_step = f'''\n",
    "        Details -\n",
    "            Analysis to perform: {my_analysis}\n",
    "            Preprocessing step: {key}\n",
    "            Preprocessing Details: {re.findall(rf'> {key}:-(.*?)>', preprocessing_template, re.DOTALL)[0]}\n",
    "            Columns: {columns_intel}\n",
    "            Description of data: {data.describe()}\n",
    "            Data types of columns: {data.dtypes}\n",
    "        \n",
    "        Adhere to below instructions at all costs!\n",
    "        Instructions -\n",
    "        0. Consider the details shared above for rules of your preprocessing test if required\n",
    "        1. Assume the dataframe \"data\" exists already\n",
    "        2. Do not read or generate data by yourself\n",
    "        3. Do not mention python language in your response\n",
    "        4. Write simple code that's easy to understand without any errors\n",
    "        5. Write a function that performs the preprocessing and return the dataframe after preprocessing it\n",
    "        6. Only write the code don't include any other text. The code shouldn't have any error be syntactical or logical\n",
    "        7. Call the function. Make sure you don't return an empty dataframe.\n",
    "        8. Don't use lambda function to write your code at any cost!\n",
    "        9. From the function name it should be understandable which preprocessing technique was used.\n",
    "        '''\n",
    "        count = 0\n",
    "\n",
    "        # Automated debugging\n",
    "        while count<2:\n",
    "            try:\n",
    "                if count==0:\n",
    "                    prep_code_output = generate_response(write_code_for_prep_step, temperature, safety_setting)\n",
    "                if count!=0:\n",
    "                    pass\n",
    "                prep_code_output = prep_code_output.replace('`','')\n",
    "                exec(prep_code_output)\n",
    "                break\n",
    "            \n",
    "            except Exception as e:\n",
    "                error_message = f'''\n",
    "                Code:\n",
    "                {write_code_for_prep_step}\n",
    "                Traceback of the code: {traceback.format_exc()}\n",
    "\n",
    "                Adhere to below instructions at all costs!\n",
    "                Instruction:\n",
    "                1. Identify the cause of the error and rewrite the code - make it error free\n",
    "                2. Don't include any text in your response\n",
    "                3. Rewrite the code as a function\n",
    "                4. Follow these instructions by all means\n",
    "                '''\n",
    "                temperature += 0.2\n",
    "                write_code_for_prep_step = generate_response(write_code_for_prep_step, temperature, safety_setting)\n",
    "                write_code_for_prep_step = write_code_for_prep_step.replace('python', '')\n",
    "                write_code_for_prep_step = write_code_for_prep_step.replace('`', '')\n",
    "                count+=1\n",
    "        \n",
    "        code_transcript+=prep_code_output+'\\n-----------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 countries by population\n",
      "Always Include: Relevant numbers/figures associated with the analysis.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>pop2022</th>\n",
       "      <th>pop2023</th>\n",
       "      <th>pop2030</th>\n",
       "      <th>pop2050</th>\n",
       "      <th>iso_codes_alpha_3_generated</th>\n",
       "      <th>pop_growth_2022_2023</th>\n",
       "      <th>pop_growth_2023_2030</th>\n",
       "      <th>pop_growth_2030_2050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1417173173</td>\n",
       "      <td>1428627663</td>\n",
       "      <td>1514994080</td>\n",
       "      <td>1670490596</td>\n",
       "      <td>IND</td>\n",
       "      <td>11454490</td>\n",
       "      <td>86366417</td>\n",
       "      <td>155496516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>2</td>\n",
       "      <td>1425887337</td>\n",
       "      <td>1425671352</td>\n",
       "      <td>1415605906</td>\n",
       "      <td>1312636325</td>\n",
       "      <td>CHN</td>\n",
       "      <td>-215985</td>\n",
       "      <td>-10065446</td>\n",
       "      <td>-102969581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>3</td>\n",
       "      <td>338289857</td>\n",
       "      <td>339996563</td>\n",
       "      <td>352162301</td>\n",
       "      <td>375391963</td>\n",
       "      <td>USA</td>\n",
       "      <td>1706706</td>\n",
       "      <td>12165738</td>\n",
       "      <td>23229662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>4</td>\n",
       "      <td>275501339</td>\n",
       "      <td>277534122</td>\n",
       "      <td>292150100</td>\n",
       "      <td>317225213</td>\n",
       "      <td>IDN</td>\n",
       "      <td>2032783</td>\n",
       "      <td>14615978</td>\n",
       "      <td>25075113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>5</td>\n",
       "      <td>235824862</td>\n",
       "      <td>240485658</td>\n",
       "      <td>274029836</td>\n",
       "      <td>367808468</td>\n",
       "      <td>PAK</td>\n",
       "      <td>4660796</td>\n",
       "      <td>33544178</td>\n",
       "      <td>93778632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  rank     pop2022     pop2023     pop2030     pop2050  \\\n",
       "0          India     1  1417173173  1428627663  1514994080  1670490596   \n",
       "1          China     2  1425887337  1425671352  1415605906  1312636325   \n",
       "2  United States     3   338289857   339996563   352162301   375391963   \n",
       "3      Indonesia     4   275501339   277534122   292150100   317225213   \n",
       "4       Pakistan     5   235824862   240485658   274029836   367808468   \n",
       "\n",
       "  iso_codes_alpha_3_generated  pop_growth_2022_2023  pop_growth_2023_2030  \\\n",
       "0                         IND              11454490              86366417   \n",
       "1                         CHN               -215985             -10065446   \n",
       "2                         USA               1706706              12165738   \n",
       "3                         IDN               2032783              14615978   \n",
       "4                         PAK               4660796              33544178   \n",
       "\n",
       "   pop_growth_2030_2050  \n",
       "0             155496516  \n",
       "1            -102969581  \n",
       "2              23229662  \n",
       "3              25075113  \n",
       "4              93778632  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(my_analysis)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 countries by population\n",
      "Always Include: Relevant numbers/figures associated with the analysis.\n"
     ]
    }
   ],
   "source": [
    "# Perform analysis - \n",
    "print(my_analysis)\n",
    "write_code_for_analysis = ''\n",
    "count, temperature = 0, 0\n",
    "while count<2:\n",
    "    try:\n",
    "        query = f'''\n",
    "        Task: {my_analysis}\n",
    "        Remember: Analysis is always some type of aggregation or group of certain columns to get the desired result.\n",
    "\n",
    "        Instructions:\n",
    "        1. Write a function in python to execute the task and call the function to execute the code - at all costs\n",
    "        2. Assume a dataframe with the name \"data\" already exists.\n",
    "        3. Dataframe df has the following columns: {data.columns}. Use the column names for your refernece while generating the code.\n",
    "        4. Don't include the code to read the file. Write the code assuming the dataframe already exists.\n",
    "        5. Don't generate your own data. But if column \"iso_codes_alpha_3_generated\" is present then don't drop it by any chance.\n",
    "        6. First 5 rows of the dataframe you will work on: {data.head(5)}\n",
    "        7. Dataframe should have {data.columns} as its columns only.\n",
    "        8. Don't write code to train any machine learning model. Write code only to perform the analysis\n",
    "        9. Save the output of the analysis a csv file: 'analysis_result.csv' at all costs!\n",
    "\n",
    "        Expected output:\n",
    "        def some_function_name():\n",
    "        # Logic\n",
    "\n",
    "        return data\n",
    "\n",
    "        data = some_function_name()\n",
    "        '''\n",
    "        if count==0:\n",
    "            write_code_for_analysis = generate_response(query, temperature, safety_setting)\n",
    "        write_code_for_analysis = write_code_for_analysis.replace('python', '')\n",
    "        write_code_for_analysis = write_code_for_analysis.replace('`','')\n",
    "        exec(write_code_for_analysis)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        error_message = f'''\n",
    "            Code:\n",
    "            {write_code_for_analysis}\n",
    "            Traceback of the code: {traceback.format_exc()}\n",
    "\n",
    "            Adhere to below instructions at all costs!\n",
    "            Instruction:\n",
    "            1. Identify the cause of the error and rewrite the code - make it error free\n",
    "            2. Don't include any text in your response\n",
    "            3. Rewrite the code as a function\n",
    "            4. Follow these instructions by all means\n",
    "            '''\n",
    "        temperature += 0.2\n",
    "        write_code_for_analysis = generate_response(error_message, 0.5, safety_setting)\n",
    "        count+=1\n",
    "        \n",
    "    code_transcript+=write_code_for_analysis+'\\n-----------------------------------------\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visualization'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insight type identification\n",
    "\n",
    "analysis_output = open('analysis_result.csv').read()\n",
    "insight_prompt = f'''\n",
    "Based on the Analysis Output shared below, tell what would be best way to represent the insights of the given analysis - Visualization or Text\n",
    "1. Choose Visualization when the number of fields are less and thus the chart formed would be readable to user.\n",
    "2. Choose Text when the number of values are more or the output length is long.\n",
    "\n",
    "Expected Output: Visualization or Text\n",
    "Analysis wanted: {my_analysis}\n",
    "Analysis Output: {analysis_output}\n",
    "'''\n",
    "\n",
    "insight_choice = generate_response(insight_prompt, temperature, safety_setting)\n",
    "insight_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Population in 2022"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ],
         "locations": [
          "IND",
          "CHN",
          "USA",
          "IDN",
          "PAK",
          "NGA",
          "BRA",
          "BGD",
          "Russia",
          "MEX",
          "ETH",
          "JPN",
          "PHL",
          "EGY",
          "DR Congo"
         ],
         "text": [
          "India",
          "China",
          "United States",
          "Indonesia",
          "Pakistan",
          "Nigeria",
          "Brazil",
          "Bangladesh",
          "Russia",
          "Mexico",
          "Ethiopia",
          "Japan",
          "Philippines",
          "Egypt",
          "DR Congo"
         ],
         "type": "choropleth",
         "z": [
          1417173173,
          1425887337,
          338289857,
          275501339,
          235824862,
          218541212,
          215313498,
          171186372,
          144713314,
          127504125,
          123379924,
          123951692,
          115559009,
          110990103,
          99010212
         ]
        }
       ],
       "layout": {
        "geo": {
         "projection": {
          "type": "orthographic"
         },
         "showframe": false
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 15 Countries by Population in 2022"
        },
        "width": 700
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. \tIndia is the most populous country in the world with a population of over 1.4 billion people.\n",
      "\n",
      "\n",
      "2. \tChina is the second most populous country in the world with a population of over 1.4 billion people.\n",
      "\n",
      "\n",
      "3. \tThe United States is the third most populous country in the world with a population of over 338 million people.\n",
      "\n",
      "\n",
      "4. \tIndonesia is the fourth most populous country in the world with a population of over 275 million people.\n",
      "\n",
      "\n",
      "5. \tPakistan is the fifth most populous country in the world with a population of over 235 million people.\n",
      "\n",
      "\n",
      "6. \tBrazil is the sixth most populous country in the world with a population of over 215 million people.\n",
      "\n",
      "\n",
      "7. \tBangladesh is the seventh most populous country in the world with a population of over 171 million people.\n",
      "\n",
      "\n",
      "8. \tRussia is the eighth most populous country in the world with a population of over 144 million people.\n",
      "\n",
      "\n",
      "9. \tMexico is the ninth most populous country in the world with a population of over 127 million people.\n",
      "\n",
      "\n",
      "10. \tEthiopia is the tenth most populous country in the world with a population of over 123 million people.\n",
      "\n",
      "\n",
      "11. \tJapan is the eleventh most populous country in the world with a population of over 123 million people.\n",
      "\n",
      "\n",
      "12. \tThe Philippines is the twelfth most populous country in the world with a population of over 115 million people.\n",
      "\n",
      "\n",
      "13. \tEgypt is the thirteenth most populous country in the world with a population of over 110 million people.\n",
      "\n",
      "\n",
      "14. \tDR Congo is the fourteenth most populous country in the world with a population of over 99 million people.\n",
      "\n",
      "\n",
      "15. \tNigeria is the fifteenth most populous country in the world with a population of over 218 million people.\n",
      "\n",
      "\n",
      "16. \tThe world's population is expected to grow from 8 billion in 2023 to 9.7 billion in 2050.\n",
      "\n",
      "\n",
      "17. \tThe top 15 countries by population are home to over half of the world's population.\n",
      "\n",
      "\n",
      "18. \tThe top 15 countries by population are all located in different parts of the world.\n",
      "\n",
      "\n",
      "19. \tThe top 15 countries by population are all facing different challenges and opportunities.\n",
      "\n",
      "\n",
      "20. \tThe top 15 countries by population are all important players in the global economy.\n",
      "\n",
      "\n",
      "21. \tThe top 15 countries by population are all worth watching in the years to come.\n"
     ]
    }
   ],
   "source": [
    "def generate_response_gemini_image(prompt, img):\n",
    "        response = model_cv.generate_content([prompt, img], stream=True)\n",
    "        response.resolve()\n",
    "        return re.sub(r\"\\*\\*([^*]+)\\*\\*\", r\"\\1\", response.text)\n",
    "\n",
    "# To give insights\n",
    "def understand_image(img):\n",
    "    prompt = f'''\n",
    "    Analysis requested: {my_analysis}\n",
    "    Analysis Output: {analysis_output}\n",
    "    Data: {data.columns}\n",
    "\n",
    "    The given image is extracted from the analysis. It is a type of visualisation. \n",
    "    If visualization: \n",
    "        1. Identify the type of visualization\n",
    "        2. Using labels and legends extract important and accurate insights with numerical figures or percentages from the visualization if there are any.\n",
    "        3. The insights should be interesting, accurate and actionable - related to the analysis mentioned.\n",
    "    \n",
    "    Instructions:\n",
    "    1. Make sure above conditions are met.\n",
    "    2. Do not include anything else in your response. \n",
    "    3. Be concise, crisp and concrete. Write insights creatively. Each new insight shouldn't start the same way. Make every insight's beginning look unique.\n",
    "    4. Refer output analysis to generate actionable insights based on the analysis asked and give business related suggestion if asked.\n",
    "    '''\n",
    "    return generate_response_gemini_image(prompt, img)\n",
    "\n",
    "# Code to generate charts\n",
    "if insight_choice=='Visualization':\n",
    "    count, temperature = 0, 0\n",
    "    # vis_code = ''\n",
    "    while count<2:\n",
    "        try:\n",
    "            visualization_prompt = f'''\n",
    "                Information - \n",
    "                Task: {my_analysis}\n",
    "                Output: {analysis_output}\n",
    "\n",
    "                TYPES OF CHARTS:\n",
    "                1. Line Chart: Good for trends over time/categories, bad for many data points or complex relationships.\n",
    "                2. Bar Chart: Compares categories/frequencies, avoid for many categories or negative values.\n",
    "                3. Scatter Plot: Explores relationships between two variables, not ideal for more than 3 variables or unclear patterns.\n",
    "                4. Pie Chart: Shows proportions of a whole, avoid for many categories or unclear comparisons.\n",
    "                5. Histogram: Visualizes distribution of continuous data, not for categorical data.\n",
    "                6. Box Plot: Compares distributions across categories, avoid if outliers dominate.\n",
    "                7. Heatmap: Good for visualizing relationships between many variables, bad for complex data, overwhelming for large datasets\n",
    "                8. Word cloud: good for visual exploration of frequent terms in text data, bad for in-depth analysis.\n",
    "                9. Network Graph: Shows connections between entities (e.g., social networks, protein interactions), Not ideal for large or dense networks.\n",
    "                10. Sankey Diagram: Tracks flows across stages in a process (e.g., customer journeys, material flow). Gets messy with many stages or branches.\n",
    "                11. Choropleth Mapbox: Colors geographic regions like country etc based on a data value (e.g., election results, population density). Avoids if data varies greatly within regions.\n",
    "                12. Heatmap (Geographic): Colors geographic areas based on data intensity. Overwhelming for cluttered data or small regions.\n",
    "                13. Flow Map: Shows movement between geographic locations (e.g., migration patterns, trade routes). Can get confusing with many flows or overlapping paths.\n",
    "\n",
    "                DEFAULT CHARTS (They are default charts but you can overrule and plot a different chart if you think it would improve readability to user)-:\n",
    "                1. Trends over time/categories: Line chart\n",
    "                2. Compare categories/frequencies: Bar Chart\n",
    "                3. Compare frequency but also has regions like countries involved: Choropleth Mapbox plot (Use ISO code alpha 3) - using plotly.graph_objects;\n",
    "                4. To show proportions: Pie chart\n",
    "                5. Comparing distribution: Box plot\n",
    "                6. Visualizing distribution of continous data: Histogram (Geographic) or Choropleth\n",
    "                7. Exploration of frequent terms in text data: Word cloud\n",
    "\n",
    "                Follow the instructions by all means.\n",
    "                Instructions -\n",
    "                0. Based on the info available above identify what type of chart would suit the best to convey the insights for \"{my_analysis}\" - consider readability of the chart as well.\n",
    "                1. Write code in python to perform an insightful visualization from the output shared to plot it - call the function at costs. Don't write any other text. Just code.\n",
    "                2. Make a new dataframe which has the following data: {analysis_output} and columns: {data.columns} from 'analysis_result.csv'\n",
    "                3. Don't generate your own data. Don't equate visualization with \"data\" variable at any cost.\n",
    "                4. Visualization should have title, axis labels, legend etc.\n",
    "                5. Save the visualization with the name 'viz.png' and 'viz.html' as well at all costs in the function itself.\n",
    "                6. Always show x axis labels with a rotation of 90 degrees if the number of labels are more than 8\n",
    "                7. If the chart can be built using Seaborn, Geopandas or Plotly then use it\n",
    "                8. Refer Code trascript: {code_transcript} to write an error free code\n",
    "                9. If number of entities/rows representing are more then plot only the first/top 10 rows (and mention it in the graph that you have done it)\n",
    "\n",
    "                Expected output:\n",
    "                def name_of_visualization(some_parameters):\n",
    "                    # Some Logic\n",
    "\n",
    "                    # Code to plot and show the chart\n",
    "                    \n",
    "                    # Code to save the chart/figure with name \"Viz.png\" and \"Viz.html\"\n",
    "                \n",
    "                # calling the function by all means\n",
    "                name_of_visualization(some_parameters)\n",
    "                '''\n",
    "            if count==0:\n",
    "                vis_code = generate_response(visualization_prompt, temperature, safety_setting)\n",
    "            vis_code = vis_code.replace('python', '')\n",
    "            vis_code = vis_code.replace('`', '')\n",
    "            exec(vis_code)\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = f'''\n",
    "                Code: {vis_code}\n",
    "                Traceback of the code: {traceback.format_exc()}\n",
    "\n",
    "                Adhere to below instructions at all costs!\n",
    "                Instruction:\n",
    "                1. Identify the cause of the error and rewrite the code - make it error free\n",
    "                2. Don't include any text in your response\n",
    "                3. Rewrite the code as a function\n",
    "                4. Follow these instructions by all means\n",
    "                '''\n",
    "            temperature += 0.2\n",
    "            vis_code = generate_response(error_message, temperature, safety_setting)\n",
    "        count+=1\n",
    "    \n",
    "    code_transcript += vis_code+'\\n-----------------------------------------\\n'\n",
    "\n",
    "    model_cv = genai.GenerativeModel('gemini-pro-vision')\n",
    "    all_items = os.listdir()\n",
    "    if 'viz.png' in all_items:\n",
    "        img = Image.open('viz.png')\n",
    "    else:\n",
    "         pass\n",
    "    viz_insight = understand_image(img)\n",
    "    print(viz_insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if insight_choice=='Text':\n",
    "    textual_insight = f'''\n",
    "                        Action: Read the analysis output of {my_analysis} carefully: {analysis_output}\n",
    "\n",
    "                        Instructions:\n",
    "                        1. Share the results and give concrete and crisp actionable or interesting insights from it.\n",
    "                        2. Tone: Professional\n",
    "                        3. Talk always in terms of numbers/figures or percentages'''\n",
    "\n",
    "    insights = generate_response(textual_insight, 0.5, safety_setting)\n",
    "    print(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: (in mins) 1.7290872852007548\n"
     ]
    }
   ],
   "source": [
    "print('Execution Time: (in mins)',(time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
